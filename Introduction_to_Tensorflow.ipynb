{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhawvipul/Reinforcement-Learning-Lectures/blob/master/Introduction_to_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM_JhgjL0g5F",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Tensorflow\n",
        "\n",
        "Developed by Google Brain . Written in Python, c++ and CUDA.\n",
        "\n",
        "![Tensorflow Logo](https://www.tensorflow.org/_static/images/tensorflow/logo.png)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Tensorflow framework is composed of two things - \n",
        "\n",
        "1.   A library for defining computational graphs\n",
        "2.   A runtime for executing the graphs on different hardwares\n",
        "\n",
        "## What are computational Graphs?\n",
        "\n",
        "Computational graphs are an abstract way to represent or describe computation as directed graph:\n",
        "\n",
        "*   Edges are **tensors** or multi-dimensional arrays\n",
        "*   Nodes are rules or **Ops** which manipulates the tensors.\n",
        "\n",
        "Let us understand the computational graphs a bit more - \n",
        "\n",
        "Suppose we have to execute following operations - \n",
        "\n",
        "```\n",
        "a = 10\n",
        "\n",
        "b = 20 \n",
        "\n",
        "temp1 = a + b\n",
        "\n",
        "temp2 = a*b\n",
        "\n",
        "result = temp2/temp1\n",
        "\n",
        "print result\n",
        "```\n",
        "\n",
        "Now for the mentioned flow, this is how a computational graph will look like - \n",
        "\n",
        "[Click here to see the computational graph](https://github.com/vaibhawvipul/Reinforcement-Learning-Lectures/blob/master/TF-Comp-graph.png)\n",
        "\n",
        "This representation helps tensorflow to compute dependencies in the graph and allows the tensorflow backend to parallelize the processes on multiple cores on your system.\n",
        "It gives very high performance with no inputs from user about the code execution.\n",
        "\n",
        "Now let us see how can we define the graph shown above in tensorflow - \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06-5JX2BzyLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10bOPRBo0Z21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining a and b\n",
        "a = tf.constant(10)\n",
        "b = tf.constant(20)\n",
        "\n",
        "# defining some more ops\n",
        "temp1 = tf.add(a,b)\n",
        "temp2 = tf.multiply(a,b)\n",
        "\n",
        "result = tf.divide(temp2,temp1)\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkGmah8ZAUYL",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow supports various forms of computation - stateful, conditional, iterative, async.\n",
        "\n",
        "All the above forms of computations are supported because of variety of **ops** tensorflow provides.\n",
        "\n",
        "\n",
        "*   **Variable** - to read and update the writable values that persists across execution.\n",
        "*   **Conditional**\n",
        "*   **Loop**\n",
        "*   **Control**\n",
        "*   **Queue**\n",
        "\n",
        "---\n",
        "\n",
        "## Definition vs Execution\n",
        "\n",
        "A tensorflow program consists of two parts - \n",
        "\n",
        "*   Definition\n",
        "*   Execution\n",
        "\n",
        "`tf.Graph` is used to specify computations. `tf.Session` is responsible for executing sessions.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## tf.Graph\n",
        "\n",
        "It is used to descibe computation using Ops and Tensors.\n",
        "\n",
        "A tensor may have shape and data type but no actual data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4B9e5k4ALeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1000000000000x1000000000000\n",
        "a = tf.zeros((int(1e12), int(1e12))) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihORfpJSlHo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# following won't work, It will give OOM error\n",
        "import numpy as np\n",
        "np.zeros((int(1e12), int(1e12)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MACf7GcSlybJ",
        "colab_type": "text"
      },
      "source": [
        "Tensor shapes can be derived from the graph(shape inference)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBlUDSB0lXDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.zeros((10,10)) #10X10 shape\n",
        "\n",
        "b = tf.concat([a,a],axis=0)\n",
        "b.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_vZN_WamPMZ",
        "colab_type": "text"
      },
      "source": [
        "## tf.Session\n",
        "\n",
        "This actually executes the graph. It does the computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50p_XPuzltaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.constant(1.0)\n",
        "b = tf.constant(1.0)\n",
        "c = tf.constant(4.0)\n",
        "\n",
        "d = tf.divide(c,tf.add(a,b))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run(d))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NdjijIiueqv",
        "colab_type": "text"
      },
      "source": [
        "## Execution model\n",
        "\n",
        "`sess.run()` identifies and executes the smallest set of nodes required to compute the requested tensor.\n",
        "\n",
        "## Programming Languages - \n",
        "\n",
        "\n",
        "1.   Python\n",
        "2.   C++\n",
        "3.   Rust\n",
        "4.   GO\n",
        "5.   Java\n",
        "\n",
        "No matter which language you choose, most of the computation will happen on the highly optimized tensorflow C++ backend.\n",
        "\n",
        "## Variable Initializer - \n",
        "\n",
        "One can initialize all the vaiable at once like \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb6KUgUEuUXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVUh-U_OwLHX",
        "colab_type": "text"
      },
      "source": [
        "## Placeholders and Feeds \n",
        " \n",
        "Placeholders are used to insert data in the graph at runtime.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CjH0N6fwCnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.compat.v1.placeholder(tf.float32, shape=(1024, 1024))\n",
        "y = tf.matmul(x, x)\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  #print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
        "\n",
        "  rand_array = np.random.rand(1024, 1024)\n",
        "  print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swIylPY7wstM",
        "colab_type": "text"
      },
      "source": [
        "Notes - \n",
        "\n",
        "1. Using placeholder is manully intensive\n",
        "2. Gives us a lor of flexibility\n",
        "3. tf.data is better option"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4o-AU5cxMfR",
        "colab_type": "text"
      },
      "source": [
        "# Writing first neural network in keras with tf backend\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7IXsOIEwhS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "#print len(X_train)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2] #m X n array where m = n = 28\n",
        "#print num_pixels #print 784\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "#print X_train\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "#print y_train\n",
        "\n",
        "# define baseline model\n",
        "def baseline_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\t# Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}